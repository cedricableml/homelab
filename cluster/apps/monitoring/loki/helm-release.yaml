---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: loki
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://grafana.github.io/helm-charts
      chart: loki
      version: 2.6.0
      sourceRef:
        kind: HelmRepository
        name: grafana-charts
        namespace: flux-system
      interval: 5m
  values:
    image:
      repository: ghcr.io/k8s-at-home/loki
    ingress:
      enabled: true
      ingressClassName: "traefik"
      annotations:
        external-dns.alpha.kubernetes.io/target: "traefik.${SECRET_DOMAIN}"
        external-dns.alpha.kubernetes.io/cloudflare-proxied: "false"
      hosts:
        - host: "loki.local.${SECRET_DOMAIN}"
          paths:
            - /
      tls:
      - hosts:
        - "loki.local.${SECRET_DOMAIN}"
    serviceMonitor:
      enabled: true
    config:
      ruler:
        storage:
          type: local
          local:
            directory: /rules
        rule_path: /tmp/scratch
        alertmanager_url: http://prometheus-alertmanager:9093
        ring:
          kvstore:
            store: inmemory
        enable_api: true
    alerting_groups:
    #
    # SMART Failures
    #
    - name: smart-failure
      rules:
      - alert: SmartFailures
        expr: |
          sum by (hostname) (count_over_time({hostname=~".+"} |~ "(?i).*smartd.*(error|fail).*"[2m])) > 0
        for: 10s
        labels:
          severity: critical
          category: logs
        annotations:
          summary: "SMART has reported failures a drive on {{$hostname}}"
    #
    # *arr applications
    #
    - name: arr
      rules:
      - alert: ArrDatabaseIsLocked
        expr: |
          sum by (app) (count_over_time({app=~".*arr"} |~ "(?i)database is locked"[2m])) > 0
        for: 10s
        labels:
          severity: critical
          category: logs
        annotations:
          summary: "{{$app}} is experiencing locked database issues"
